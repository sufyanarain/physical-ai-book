"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[9833],{3196:e=>{e.exports=JSON.parse('{"version":{"pluginId":"docs-software","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/physical-ai-book/docs-software/intro","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro","unlisted":false},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/physical-ai-book/docs-software/module-1/ros2-intro","label":"Introduction to ROS 2","docId":"module-1/ros2-intro","unlisted":false},{"type":"link","href":"/physical-ai-book/docs-software/module-1/ros2-fundamentals","label":"ROS 2 Fundamentals","docId":"module-1/ros2-fundamentals","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/physical-ai-book/docs-software/module-2/simulation-intro","label":"Introduction to Robot Simulation","docId":"module-2/simulation-intro","unlisted":false},{"type":"link","href":"/physical-ai-book/docs-software/module-2/gazebo-unity","label":"Gazebo & Unity Integration","docId":"module-2/gazebo-unity","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/physical-ai-book/docs-software/module-3/isaac-intro","label":"Introduction to NVIDIA Isaac","docId":"module-3/isaac-intro","unlisted":false},{"type":"link","href":"/physical-ai-book/docs-software/module-3/isaac-advanced","label":"Isaac Advanced Topics","docId":"module-3/isaac-advanced","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/physical-ai-book/docs-software/module-4/vla-intro","label":"Vision-Language-Action (VLA)","docId":"module-4/vla-intro","unlisted":false},{"type":"link","href":"/physical-ai-book/docs-software/module-4/capstone-project","label":"Capstone Project: Autonomous Humanoid","docId":"module-4/capstone-project","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to Physical AI & Humanoid Robotics \u2014 your comprehensive guide to bridging the gap between digital intelligence and the physical world. As a software developer, you\'re likely familiar with programming concepts like Python, object-oriented programming, and algorithms. However, working with physical systems requires an understanding of hardware and electronics concepts. Think of it like this: just as software has its own set of rules and protocols, physical systems have their own set of physical laws and principles that govern their behavior.","sidebar":"tutorialSidebar"},"module-1/ros2-fundamentals":{"id":"module-1/ros2-fundamentals","title":"ROS 2 Fundamentals","description":"Deep dive into advanced ROS 2 concepts for building production-ready robotic systems. As a software developer, you\'re likely familiar with programming concepts like object-oriented programming (OOP), algorithms, and data structures. However, working with robots requires understanding hardware and electronics concepts, such as circuits, sensors, actuators, motors, and mechanical systems. In this documentation, we\'ll provide explanations and analogies to help you bridge the gap between software and hardware.","sidebar":"tutorialSidebar"},"module-1/ros2-intro":{"id":"module-1/ros2-intro","title":"Introduction to ROS 2","description":"ROS 2 (Robot Operating System 2) is the middleware backbone of modern robotics, enabling different parts of a robot to communicate seamlessly. It acts as the \\"nervous system\\" that connects sensors (which detect environmental changes), actuators (which perform actions), and intelligence (which makes decisions). To understand ROS 2, it\'s essential to grasp the basics of robotics hardware and electronics.","sidebar":"tutorialSidebar"},"module-2/gazebo-unity":{"id":"module-2/gazebo-unity","title":"Gazebo & Unity Integration","description":"Advanced simulation techniques combining Gazebo\'s physics with Unity\'s visualization. This integration allows for the creation of realistic and dynamic simulations, which is crucial for robotics development. To understand this concept, let\'s break down the components involved:","sidebar":"tutorialSidebar"},"module-2/simulation-intro":{"id":"module-2/simulation-intro","title":"Introduction to Robot Simulation","description":"Simulation is the bridge between theory and practice in robotics. Before deploying expensive hardware, we test in virtual environments called Digital Twins. Think of a Digital Twin like a virtual prototype of your robot, where you can test and refine its behavior without the risks and costs associated with physical prototypes.","sidebar":"tutorialSidebar"},"module-3/isaac-advanced":{"id":"module-3/isaac-advanced","title":"Isaac Advanced Topics","description":"Deep dive into advanced Isaac capabilities for production robotics. This module will cover complex topics such as multi-robot coordination, cloud deployment, and performance optimization. To understand these concepts, it\'s essential to have a basic grasp of robotics and electronics principles.","sidebar":"tutorialSidebar"},"module-3/isaac-intro":{"id":"module-3/isaac-intro","title":"Introduction to NVIDIA Isaac","description":"NVIDIA Isaac is the AI robot platform accelerating robotics development with GPU-powered perception, simulation, and manipulation. This platform is designed to streamline the development process of robotics applications by providing a comprehensive set of tools and libraries.","sidebar":"tutorialSidebar"},"module-4/capstone-project":{"id":"module-4/capstone-project","title":"Capstone Project: Autonomous Humanoid","description":"Build a complete autonomous humanoid robot system integrating all course concepts.","sidebar":"tutorialSidebar"},"module-4/vla-intro":{"id":"module-4/vla-intro","title":"Vision-Language-Action (VLA)","description":"The convergence of Large Language Models (LLMs) and robotics enables natural language robot control. This integration allows robots to understand and execute tasks based on verbal commands, making them more accessible and user-friendly.","sidebar":"tutorialSidebar"}}}}')}}]);