"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[815],{8382:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3/isaac-intro","title":"Introduction to NVIDIA Isaac","description":"NVIDIA Isaac is the AI robot platform accelerating robotics development with GPU-powered perception, simulation, and manipulation. This platform is designed to streamline the development process of robotics applications by providing a comprehensive set of tools and libraries.","source":"@site/docs-software/module-3/isaac-intro.md","sourceDirName":"module-3","slug":"/module-3/isaac-intro","permalink":"/docs-software/module-3/isaac-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/sufyanarain/physical-ai-book/tree/main/website/docs-software/module-3/isaac-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo & Unity Integration","permalink":"/docs-software/module-2/gazebo-unity"},"next":{"title":"Isaac Advanced Topics","permalink":"/docs-software/module-3/isaac-advanced"}}');var t=a(4848),s=a(8453);const r={sidebar_position:1},o="Introduction to NVIDIA Isaac",l={},c=[{value:"Isaac Platform Components",id:"isaac-platform-components",level:2},{value:"1. Isaac Sim",id:"1-isaac-sim",level:3},{value:"2. Isaac ROS",id:"2-isaac-ros",level:3},{value:"3. Isaac SDK",id:"3-isaac-sdk",level:3},{value:"Why NVIDIA Isaac?",id:"why-nvidia-isaac",level:2},{value:"Setting Up Isaac Sim",id:"setting-up-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation",id:"installation",level:3},{value:"Creating a Robot in Isaac Sim",id:"creating-a-robot-in-isaac-sim",level:2},{value:"Import URDF",id:"import-urdf",level:3},{value:"Add Sensors",id:"add-sensors",level:3},{value:"Isaac ROS for Real Robots",id:"isaac-ros-for-real-robots",level:2},{value:"Visual SLAM (VSLAM)",id:"visual-slam-vslam",level:3},{value:"Object Detection",id:"object-detection",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Nav2 with Isaac",id:"nav2-with-isaac",level:2},{value:"Manipulation with Isaac",id:"manipulation-with-isaac",level:2},{value:"Grasp Planning",id:"grasp-planning",level:3},{value:"Motion Planning (RMPflow)",id:"motion-planning-rmpflow",level:3},{value:"Training with Isaac Sim",id:"training-with-isaac-sim",level:2},{value:"Reinforcement Learning",id:"reinforcement-learning",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"introduction-to-nvidia-isaac",children:"Introduction to NVIDIA Isaac"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"NVIDIA Isaac"})," is the AI robot platform accelerating robotics development with GPU-powered perception, simulation, and manipulation. This platform is designed to streamline the development process of robotics applications by providing a comprehensive set of tools and libraries."]}),"\n",(0,t.jsx)(n.h2,{id:"isaac-platform-components",children:"Isaac Platform Components"}),"\n",(0,t.jsx)(n.h3,{id:"1-isaac-sim",children:"1. Isaac Sim"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim is a photorealistic robot simulation built on NVIDIA Omniverse. It provides a realistic environment for testing and training robots, reducing the need for physical prototypes and accelerating the development process. Key features of Isaac Sim include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ray tracing"}),": Physically accurate lighting that simulates the way light interacts with objects in the real world. This is similar to how graphics rendering works in video games, but with a focus on realistic lighting."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Physics"}),": PhysX 5.0 engine, which simulates the physical behavior of objects in the environment. This engine is responsible for simulating collisions, friction, and other physical interactions between objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synthetic data"}),": Perfect ground truth for AI training, which eliminates the need for manual data labeling. Synthetic data is generated by the simulation and can be used to train machine learning models."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-isaac-ros",children:"2. Isaac ROS"}),"\n",(0,t.jsx)(n.p,{children:"Isaac ROS is a set of hardware-accelerated ROS 2 packages that provide advanced perception capabilities for robots. ROS (Robot Operating System) is an open-source software framework that provides a set of tools and libraries for building robot applications. Key features of Isaac ROS include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"VSLAM"}),": Visual Simultaneous Localization and Mapping, which enables robots to navigate and map their environment in real-time. VSLAM uses computer vision algorithms to track the robot's movement and build a map of the environment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Object detection"}),": Real-time AI inference, which enables robots to detect and recognize objects in their environment. Object detection uses machine learning algorithms to identify objects and classify them into different categories."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Navigation"}),": Nav2 integration, which provides a navigation system for robots to move around their environment. Nav2 is a navigation framework that provides a set of tools and libraries for building navigation systems."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-isaac-sdk",children:"3. Isaac SDK"}),"\n",(0,t.jsx)(n.p,{children:"Isaac SDK is a set of libraries for robotics applications that provide advanced manipulation, perception, and navigation capabilities. Key features of Isaac SDK include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Manipulation"}),": Grasp planning, motion control, and other manipulation capabilities that enable robots to interact with their environment. Manipulation involves the use of robotic arms or grippers to manipulate objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Perception"}),": 3D reconstruction, segmentation, and other perception capabilities that enable robots to understand their environment. Perception involves the use of sensors such as cameras, lidar, or radar to perceive the environment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Navigation"}),": Path planning, obstacle avoidance, and other navigation capabilities that enable robots to move around their environment. Navigation involves the use of algorithms to plan a path and avoid obstacles."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"why-nvidia-isaac",children:"Why NVIDIA Isaac?"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Traditional Approach"}),(0,t.jsx)(n.th,{children:"Isaac Platform"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CPU-based processing"}),(0,t.jsx)(n.td,{children:"GPU-accelerated (50x faster)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Manual dataset creation"}),(0,t.jsx)(n.td,{children:"Synthetic data generation"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Separate train/deploy"}),(0,t.jsx)(n.td,{children:"Unified workflow"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Limited scaling"}),(0,t.jsx)(n.td,{children:"Cloud/edge deployment"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"The Isaac platform provides several advantages over traditional approaches, including:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU-accelerated processing"}),": The Isaac platform uses GPU acceleration to provide faster processing speeds, which is essential for real-time robotics applications."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synthetic data generation"}),": The Isaac platform provides synthetic data generation capabilities, which eliminates the need for manual data labeling and reduces the time and cost associated with data collection."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Unified workflow"}),": The Isaac platform provides a unified workflow that integrates simulation, training, and deployment, which streamlines the development process and reduces the complexity associated with separate workflows."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cloud/edge deployment"}),": The Isaac platform provides cloud/edge deployment capabilities, which enables robots to be deployed in a variety of environments, including cloud-based and edge-based deployments."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-isaac-sim",children:"Setting Up Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU"}),": NVIDIA RTX 2080 Ti or higher, which provides the necessary processing power for simulation and rendering."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"VRAM"}),": 8GB minimum, 24GB recommended, which provides the necessary memory for simulation and rendering."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RAM"}),": 32GB minimum, which provides the necessary memory for the operating system and other applications."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OS"}),": Ubuntu 20.04/22.04 or Windows 10/11, which provides a compatible operating system for the Isaac platform."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Download from NVIDIA Omniverse\n# https://www.nvidia.com/en-us/omniverse/apps/isaac-sim/\n\n# Or use Docker\ndocker pull nvcr.io/nvidia/isaac-sim:2023.1.1\n\n# Run Isaac Sim\n./isaac-sim.sh\n"})}),"\n",(0,t.jsx)(n.h2,{id:"creating-a-robot-in-isaac-sim",children:"Creating a Robot in Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"import-urdf",children:"Import URDF"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Load robot URDF\nrobot_path = "/path/to/robot.urdf"\nadd_reference_to_stage(usd_path=robot_path, prim_path="/World/Robot")\n'})}),"\n",(0,t.jsxs)(n.p,{children:["URDF (Unified Robot Description Format) is a file format used to describe the structure and properties of a robot. The ",(0,t.jsx)(n.code,{children:"add_reference_to_stage"})," function is used to load the URDF file into the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h3,{id:"add-sensors",children:"Add Sensors"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\n\n# Create camera\ncamera = Camera(\n    prim_path="/World/Robot/Camera",\n    frequency=30,\n    resolution=(1920, 1080)\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Sensors such as cameras, lidar, or radar are used to perceive the environment and provide data for perception and navigation algorithms. The ",(0,t.jsx)(n.code,{children:"Camera"})," class is used to create a camera sensor in the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h2,{id:"isaac-ros-for-real-robots",children:"Isaac ROS for Real Robots"}),"\n",(0,t.jsx)(n.h3,{id:"visual-slam-vslam",children:"Visual SLAM (VSLAM)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install Isaac ROS VSLAM\nsudo apt install ros-humble-isaac-ros-visual-slam\n\n# Launch VSLAM\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n"})}),"\n",(0,t.jsxs)(n.p,{children:["VSLAM is a computer vision algorithm that enables robots to navigate and map their environment in real-time. The ",(0,t.jsx)(n.code,{children:"isaac_ros_visual_slam"})," package provides a VSLAM implementation that can be used with real robots."]}),"\n",(0,t.jsx)(n.h3,{id:"object-detection",children:"Object Detection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install Isaac ROS DNN Inference\nsudo apt install ros-humble-isaac-ros-dnn-inference\n\n# Run object detection\nros2 launch isaac_ros_detectnet detectnet.launch.py \\\n    model:=peoplenet\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Object detection is a computer vision algorithm that enables robots to detect and recognize objects in their environment. The ",(0,t.jsx)(n.code,{children:"isaac_ros_detectnet"})," package provides an object detection implementation that can be used with real robots."]}),"\n",(0,t.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,t.jsx)(n.p,{children:"Generate perfect training data in Isaac Sim:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\n\n# Create camera\ncamera = rep.create.camera(position=(5, 5, 5))\n\n# Randomize lighting\nwith rep.trigger.on_frame():\n    rep.randomizer.light_intensity(\n        lights=rep.get.prims(semantics="light"),\n        min_value=500,\n        max_value=2000\n    )\n\n# Capture data\nrep.orchestrator.run()\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Synthetic data generation is a process that involves generating data in a simulation environment. The ",(0,t.jsx)(n.code,{children:"replicator"})," package provides a set of tools and libraries for generating synthetic data in the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h2,{id:"nav2-with-isaac",children:"Nav2 with Isaac"}),"\n",(0,t.jsx)(n.p,{children:"Navigate autonomously using Nav2 + Isaac:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'# nav2_params.yaml\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    \ncontroller_server:\n  ros__parameters:\n    controller_frequency: 20.0\n    FollowPath:\n      plugin: "dwb_core::DWBLocalPlanner"\n      max_vel_x: 0.5\n      max_vel_theta: 1.0\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Launch navigation\nros2 launch nav2_bringup navigation_launch.py\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Nav2 is a navigation framework that provides a set of tools and libraries for building navigation systems. The ",(0,t.jsx)(n.code,{children:"nav2_bringup"})," package provides a launch file that can be used to launch the navigation system."]}),"\n",(0,t.jsx)(n.h2,{id:"manipulation-with-isaac",children:"Manipulation with Isaac"}),"\n",(0,t.jsx)(n.h3,{id:"grasp-planning",children:"Grasp Planning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.manipulators import Gripper\n\ngripper = Gripper(prim_path="/World/Robot/Gripper")\n\n# Plan grasp\ntarget_position = [0.5, 0.0, 0.3]\ngripper.apply_action(target_position)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Grasp planning is a process that involves planning a grasp for a robotic arm or gripper. The ",(0,t.jsx)(n.code,{children:"Gripper"})," class is used to create a gripper in the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h3,{id:"motion-planning-rmpflow",children:"Motion Planning (RMPflow)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from omni.isaac.motion_generation import ArticulationMotionPolicy\n\npolicy = ArticulationMotionPolicy(\n    robot_articulation,\n    physics_dt\n)\n\n# Generate collision-free trajectory\ntrajectory = policy.compute_joint_targets(target_pose)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Motion planning is a process that involves planning a motion for a robotic arm or gripper. The ",(0,t.jsx)(n.code,{children:"ArticulationMotionPolicy"})," class is used to create a motion policy in the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h2,{id:"training-with-isaac-sim",children:"Training with Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"reinforcement-learning",children:"Reinforcement Learning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from omni.isaac.gym.vec_env import VecEnvBase\n\nclass RobotEnv(VecEnvBase):\n    def reset(self):\n        # Reset robot to initial state\n        pass\n    \n    def step(self, actions):\n        # Apply actions, return observations, rewards\n        pass\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Reinforcement learning is a type of machine learning that involves training an agent to take actions in an environment to maximize a reward. The ",(0,t.jsx)(n.code,{children:"VecEnvBase"})," class is used to create a vectorized environment in the Isaac Sim environment."]}),"\n",(0,t.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(n.p,{children:["\u2705 Isaac Sim provides photorealistic simulation",(0,t.jsx)(n.br,{}),"\n","\u2705 Isaac ROS accelerates perception with GPUs",(0,t.jsx)(n.br,{}),"\n","\u2705 Synthetic data eliminates manual labeling",(0,t.jsx)(n.br,{}),"\n","\u2705 Unified platform for train-simulate-deploy"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Next:"})," ",(0,t.jsx)(n.a,{href:"./isaac-advanced",children:"Isaac Advanced Topics \u2192"})]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var i=a(6540);const t={},s=i.createContext(t);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);